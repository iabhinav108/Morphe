{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:36:08.788593Z",
     "iopub.status.busy": "2024-10-03T17:36:08.787634Z",
     "iopub.status.idle": "2024-10-03T17:36:14.064410Z",
     "shell.execute_reply": "2024-10-03T17:36:14.063405Z",
     "shell.execute_reply.started": "2024-10-03T17:36:08.788520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    roc_curve, auc, confusion_matrix, matthews_corrcoef\n",
    ")\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:36:14.066641Z",
     "iopub.status.busy": "2024-10-03T17:36:14.066215Z",
     "iopub.status.idle": "2024-10-03T17:36:14.073965Z",
     "shell.execute_reply": "2024-10-03T17:36:14.072984Z",
     "shell.execute_reply.started": "2024-10-03T17:36:14.066603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the dataset for DeepFake detection\n",
    "class DeepFakeDataset(Dataset):\n",
    "    def __init__(self, image_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_list[idx]\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if 'real' in img_name:\n",
    "            label = 0\n",
    "        elif 'deepfake' in img_name:\n",
    "            label = 1\n",
    "        else:\n",
    "            raise ValueError(f'Unknown label in file name: {img_name}')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:36:14.075705Z",
     "iopub.status.busy": "2024-10-03T17:36:14.075377Z",
     "iopub.status.idle": "2024-10-03T17:36:14.085989Z",
     "shell.execute_reply": "2024-10-03T17:36:14.085095Z",
     "shell.execute_reply.started": "2024-10-03T17:36:14.075655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to filter and randomly select images\n",
    "def select_images(root_dir, label, num_images):\n",
    "    image_list = [os.path.join(root_dir, img) for img in os.listdir(root_dir) if label in img]\n",
    "    selected_images = random.sample(image_list, num_images)\n",
    "    return selected_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:36:14.089142Z",
     "iopub.status.busy": "2024-10-03T17:36:14.088224Z",
     "iopub.status.idle": "2024-10-03T17:36:14.100375Z",
     "shell.execute_reply": "2024-10-03T17:36:14.099389Z",
     "shell.execute_reply.started": "2024-10-03T17:36:14.089096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Coordinate Attention block\n",
    "class CoordinateAttention(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, reduction=32):\n",
    "        super(CoordinateAttention, self).__init__()\n",
    "        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        self.pool_w = nn.AdaptiveAvgPool2d((1, None))\n",
    "        mip = max(8, in_channels // reduction)\n",
    "        self.conv1 = nn.Conv2d(in_channels, mip, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(mip)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv_h = nn.Conv2d(mip, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_w = nn.Conv2d(mip, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        n, c, h, w = x.size()\n",
    "        x_h = self.pool_h(x)\n",
    "        x_w = self.pool_w(x).permute(0, 1, 3, 2)\n",
    "        y = torch.cat([x_h, x_w], dim=2)\n",
    "        y = self.relu(self.bn1(self.conv1(y)))\n",
    "        x_h, x_w = torch.split(y, [h, w], dim=2)\n",
    "        x_w = x_w.permute(0, 1, 3, 2)\n",
    "        a_h = torch.sigmoid(self.conv_h(x_h))\n",
    "        a_w = torch.sigmoid(self.conv_w(x_w))\n",
    "        out = identity * a_h * a_w\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:36:14.101874Z",
     "iopub.status.busy": "2024-10-03T17:36:14.101533Z",
     "iopub.status.idle": "2024-10-03T17:36:14.110193Z",
     "shell.execute_reply": "2024-10-03T17:36:14.109398Z",
     "shell.execute_reply.started": "2024-10-03T17:36:14.101842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom DenseNet121 with Coordinate Attention\n",
    "class CustomDenseNet121(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDenseNet121, self).__init__()\n",
    "        densenet = models.densenet121(weights='DenseNet121_Weights.IMAGENET1K_V1')\n",
    "        self.features = nn.Sequential(\n",
    "            densenet.features.conv0,\n",
    "            densenet.features.norm0,\n",
    "            densenet.features.relu0,\n",
    "            densenet.features.pool0,\n",
    "            densenet.features.denseblock1,\n",
    "            densenet.features.transition1,\n",
    "            CoordinateAttention(in_channels=128, out_channels=128),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 16)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # print('shape before fc : ', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:36:14.112237Z",
     "iopub.status.busy": "2024-10-03T17:36:14.111677Z",
     "iopub.status.idle": "2024-10-03T17:36:14.126887Z",
     "shell.execute_reply": "2024-10-03T17:36:14.125855Z",
     "shell.execute_reply.started": "2024-10-03T17:36:14.112202Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Main DeepFake detection model\n",
    "class DeepFakeDetectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepFakeDetectionModel, self).__init__()\n",
    "        self.branch1 = CustomDenseNet121()\n",
    "        self.branch2 = CustomDenseNet121()\n",
    "        self.branch2.features[0] = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.branch3 = CustomDenseNet121()\n",
    "        self.fc_final = nn.Linear(48, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_edge = self.apply_canny(x)\n",
    "        x_texture = self.extract_texture(x)\n",
    "\n",
    "        out1 = self.branch1(x)\n",
    "        out2 = self.branch2(x_edge)\n",
    "        out3 = self.branch3(x_texture)\n",
    "\n",
    "        out = torch.cat([out1, out2, out3], dim=1)\n",
    "        out = self.fc_final(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def apply_canny(self, x):\n",
    "        # Convert to numpy, apply Canny edge detection, and convert back to tensor\n",
    "        x = x.permute(0, 2, 3, 1).cpu().numpy()  # BxCxHxW -> BxHxWxC\n",
    "        x_edge = []\n",
    "        for img in x:\n",
    "            edge = cv2.Canny((img * 255).astype('uint8'), 100, 200)\n",
    "            x_edge.append(edge)\n",
    "          # Convert list to numpy array\n",
    "        x_edge = torch.tensor(np.array(x_edge))\n",
    "        x_edge = x_edge.unsqueeze(1).float()\n",
    "        \n",
    "        # print('shape of edge image : ', x_edge.shape)\n",
    "        # print('type of edge matrix ', type(x_edge))\n",
    "        x_edge=x_edge.to(device)\n",
    "        return x_edge  # Move to GPU\n",
    "\n",
    "    def extract_texture(self, x):\n",
    "        # Use Laplacian for texture extraction\n",
    "        x = x.permute(0, 2, 3, 1).cpu().numpy()\n",
    "        x_texture = []\n",
    "        for img in x:\n",
    "            texture = cv2.Laplacian((img * 255).astype('uint8'), cv2.CV_64F)\n",
    "            # print('shape in texture : ', texture.shape)\n",
    "            x_texture.append(texture)\n",
    "         # Convert list to numpy array\n",
    "        tex_array = np.array(x_texture)\n",
    "        # print('shape ...... ', tex_array.shape)\n",
    "        tex_array = np.transpose(tex_array, (0, 3, 1, 2))\n",
    "        #print('updated shape : ', tex_array.shape)\n",
    "        x_texture = torch.tensor(tex_array).float()\n",
    "        # x_texture = x_texture.unsqueeze(1).float()\n",
    "        # x_texture = torch.tensor(x_texture).unsqueeze(1).float() / 255.0\n",
    "        x_texture= x_texture.to(device)\n",
    "        return x_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T17:36:14.128855Z",
     "iopub.status.busy": "2024-10-03T17:36:14.128540Z",
     "iopub.status.idle": "2024-10-03T18:09:17.560844Z",
     "shell.execute_reply": "2024-10-03T18:09:17.559838Z",
     "shell.execute_reply.started": "2024-10-03T17:36:14.128823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    root_dir = '/path/to/deepfake-detection-dataset'\n",
    "    num_samples = 64000  \n",
    "\n",
    "    # Select 32000 'real' and 32000 'deepfake' images\n",
    "    real_images = select_images(root_dir, 'real', num_samples)\n",
    "    deepfake_images = select_images(root_dir, 'deepfake', num_samples)\n",
    "\n",
    "    selected_images = real_images + deepfake_images\n",
    "    random.shuffle(selected_images)\n",
    "\n",
    "    # Define transformations\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create a dataset\n",
    "    dataset = DeepFakeDataset(image_list=selected_images, transform=data_transforms)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = DeepFakeDetectionModel().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "    # Training loop\n",
    "    def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "        best_acc = 0.0\n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "            train_losses.append(epoch_loss)\n",
    "            train_accuracies.append(epoch_acc.item())\n",
    "\n",
    "            print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            scheduler.step()\n",
    "            epoch_loss = running_loss / len(val_loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "            val_losses.append(epoch_loss)\n",
    "            val_accuracies.append(epoch_acc.item())\n",
    "\n",
    "            print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f'Total training time: {total_time:.2f} seconds')\n",
    "\n",
    "        # Save the model after training\n",
    "        torch.save(model.state_dict(), 'deepfake_detection_model.pth')\n",
    "        print(\"Model saved successfully.\")\n",
    "\n",
    "        return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
    "        model, criterion, optimizer, train_loader, val_loader, num_epochs=3\n",
    "    )\n",
    "\n",
    "    def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "        epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "    \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, train_losses, 'r', label='Training Loss')\n",
    "        plt.plot(epochs, val_losses, 'b', label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Subplot for accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, train_accuracies, 'r', label='Training Accuracy')\n",
    "        plt.plot(epochs, val_accuracies, 'b', label='Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "    \n",
    "    def evaluate_model(model, test_loader):\n",
    "        model.eval()\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]  # Get probabilities for ROC AUC\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds)\n",
    "        recall = recall_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "        mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Recall: {recall:.4f}')\n",
    "        print(f'F1 Score: {f1:.4f}')\n",
    "        print(f'ROC AUC Score: {roc_auc:.4f}')\n",
    "        print(f'Matthews Correlation Coefficient (MCC): {mcc:.4f}')\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.colorbar()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "\n",
    "        # ROC Curve\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.4f})')\n",
    "        plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5619378,
     "sourceId": 9283487,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
